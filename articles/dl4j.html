<!DOCTYPE html
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <title>Künstliche Intelligenz in Java mit Deeplearning4j</title>
    <meta http-equiv='Content-Style-Type' content='text/css' />
  <link rel='stylesheet' href='/css/jexp.css' type='text/css' />
  <link rel="openid.server" href="http://jexp.de/id" />
  <meta name='robots' content='index,follow' />
</head>
<body>
<!--PageHeaderFmt-->
  <div id='wikihead'><a href='/'><img src='/img/jexp.gif'
    alt='JEXP' border='0' align="center" /></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    JEXP</div>
<!--/PageHeaderFmt-->

<div id="wikileft">
   <ul>
	<li><a class='urllink' href='http://www.jexp.de/blog'>BLOG</a></li>
	<li><a class='urllink' href='http://github.com/jexp'>GitHub</a></li>
	<li><a class='urllink' href='/conferences.html'>Conferences</a></li>
	<li><a class='urllink' href='/articles.html'>Articles</a></li>
	<li><a class='urllink' href='/books.html'>Books</a></li>
	<li><a class='urllink' href='/projects.html'>Projects</a></li>
	<li><a class='urllink' href='/bio.html'>Bio</a></li>
</ul>

</div>

<div id="wikibody">

<h1>Künstliche Intelligenz in Java mit Deeplearning4j</h1>

<div id="preamble">
<div class="sectionbody">
<div class="imageblock">
<div class="content">
<img src="http://www.kdnuggets.com/wp-content/uploads/neural-art.jpg" alt="neural art">
</div>
</div>
<div class="paragraph">
<p>Der Hype um künstliche Intelligenz und maschinellem Lernens mittels neuronaler Netze sollte an niemandem vorbeigegangen sein.
In den letzten Jahren hat der Zuwachs an Rechenleistung und grossen Mengen verfügbaren kategorisierten Trainingsdaten es ermöglicht, Ansätze aus den letzten 40 Jahren aus dem Kälteschlaf zu erwecken und zur Anwendung zu bringen.</p>
</div>
<div class="paragraph">
<p>Wir haben diese deutlich bei den Verbesserung von Übersetzungen, Bilderkennung, Sprachsynthese und spielerischer Meisterleistung von Computerspielen bis Go erlebt.
Verstärktes Interesse und massive Finanzierung in Forschung und Anwendung haben auch zu neuen Arten von Neuronalen Netzen, wie Convolutional Neural Netzwerke (CNN) zur Bildverarbeitung, Recurrent Neuronal Netzwerke (RNN) für zeitabhängige Informationen wie Sprache, Sensordaten und Videos und Auto-Encodern zur Eigenschaftsermittlung von Eingabedaten geführt.
Gegenüber handoptimierten Methoden zur Eigenschaftsermittlung und Auswertung haben Neuronale Netze den Vorteil, dass sie relativ einfach trainierbar und generisch einsatzfähig sind.
Sie stellen eine gutes Verhältnis von Aufwand und Ergebnisqualität dar.
In der JavaSpektrum 02/2017 gab es einige Schwerpunktartikel zum Thema maschinelles Lernen.</p>
</div>
<div class="paragraph">
<p>Als Entwickler steht man dem ganzen erst einmal etwas überfordert gegenüber, kann sich aber mit etwas Durchhaltevermögen in den Wust von Begrifflichkeiten und Ansätzen aus der linearen Algebra einarbeiten.
Mir ging es ebenso und es hat einige Zeit gedauert, mit der Materie warm zu werden, meine letzen Mathematik-Semester sind auch schon mehr als 20 Jahre her.
Das Thema ein sehr weites und aktives Feld, es ist kein Wunder dass Onlinekurse, Bücher und Entwickler mit den entsprechenden Qualifikationen hoch im Kurs stehen.</p>
</div>
<div class="paragraph">
<p>Ein Großteil der Aktivität ist im Python-Umfeld zu sehen, die bekannten Frameworks wie Tensorflow, Torch, Theanos, Scikit-Learn, MxNet und ML-Lib sind alle mit Python APIs benutzbar.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_einführung">Einführung</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_klassische_vorwärtsgerichtete_netze_feed_forward">Klassische vorwärtsgerichtete Netze (feed forward)</h3>
<div class="paragraph">
<p>Neuronale Netze sind einem vereinfachtem Modell von biologischen Neuronen nachempfunden.
Informationen werden gewichtet entgegengenommen und führen beim Erreichen eine Schwellwertes zur Aktivierung nachfolgender Neuronen.
Diese sind in Schichten angeordnet von der *Eingabe*schicht mit Neuronen für jeden Eingabecharakteristik (Feature), darauf folgen mehrere versteckte (hidden) Schichten von Neuronen, deren Gewichte das Gedächtnis des Netzes darstellen.</p>
</div>
<div class="paragraph">
<p>Neuronen jeder Schicht ist zumeist mit allen Elementen der nächsten Schicht verbunden, Kanten mit einem Gewicht von Null tragen aber nicht und Kanten mit höhren Gewichten tragen entsprechend stärker zur Aktivierung der nachfolgenden Neuronen bei.
Zum Ende folgt die Ausgabeschicht, die entweder aus einem Neuron bei Regression oder binärer Klassifizierung, oder aus einem Neuron pro Klasse (Auswertung mit Wahrscheinlichkeitswert) besteht.</p>
</div>
<div class="paragraph">
<p>Neuronale Netze können sowohl zur Zuordnung von Eingaben zu einer bestimmten Anzahl von Klassen (Klassifizierung) als auch zur Vorhersage von abhängigen Ausgabewerten (Regression) genutzt werden.
Das Ziel ist, die Struktur und Essenz der Trainingsdaten zu lernen, um dann auf unbekannten Daten verlässliche Ergebnisse vorherzusagen.
Oft werden Neuronale Netze als Graphstruktur mit Knoten und gewichteten Beziehungen veranschaulicht, die Anwendung auf (GPU/Cluster)-Berechnungsplattformen ist aber mehrheitlich als Matritzenmultiplikationen umgesetzt.</p>
</div>
<div class="imageblock" style="float: right">
<div class="content">
<img src="https://upload.wikimedia.org/wikipedia/commons/c/c2/MultiLayerNeuralNetworkBigger_english.png" alt="MultiLayerNeuralNetworkBigger english" width="400">
</div>
</div>
<div class="paragraph">
<p>Die Berechnung der Ausgabe eines Neurons und des Netzes, stellt nur die pro Schicht wiederholte Anwendung einer Aktivierungsfunktion auf die Eingabesumme (<em>Summe der gewichteten Eingangswerte</em>) plus einem Basislevel (Bias).</p>
</div>
<div class="paragraph">
<p><code>Ausgabewert = Aktivierungsfunktion ( Summe (Eingangswert * Gewicht) + Bias )</code></p>
</div>
<div class="paragraph">
<p>Die Aktivierungsfunktion bildet meist den Eingabebereich auf 0..1 oder -1..1 ab und sollte gut ableitbar sein.
Beispiele sind Sigmoid (<code>1/(1+e^-x)</code>), Tanh (<code>sinh(x)/cosh(x)</code>), ReLU (Rectified Linear Unit,` 0 für x &lt; 0, sonst x`). [AktivierungsFunktionen]</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://dl.dropboxusercontent.com/u/14493611/activation-functions.jpg" alt="activation functions">
</div>
</div>
<div class="paragraph">
<p>Das spannende und komplizierte an diese Netzen ist dagegen der Trainings- und Lernmechanismus, mittels Rückkopplung (Back-Propagation).</p>
</div>
<div class="paragraph">
<p>Vereinfacht dargestellt wird pro Trainingsdatum (oder kleinem Set), die Abweichung von berechnetem und erwartetem Wert auf die Gewichte des Netzwerkes kaskadiert zurückverteilt.
Dabei wird berücksichtigt, welche Neuronen und Gewichte wie viel zum Fehler beigetragen haben.
Um eine schrittweise Annäherung an das Optimium (Minimum des Fehlers über alle Ausgaben und Trainingswerte) zu erreichen, wird der Fehleranteil noch mit einer vergleichsweise kleinen Lernrate multipliziert.
Diese Gewichtsanpassung wird wiederum ausgehend von der Ausgabe Schicht für Schicht vorgenommen, wobei die zu verteilende Fehlerabweichung pro Schicht und Neuron neu berechnet wird.</p>
</div>
<div class="paragraph">
<p>Was zeichnet <strong>Deep Learning-Netzwerke</strong> im besonderem aus?</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Höhere Anzahl an Neuronen und Schichten</p>
</li>
<li>
<p>Nicht alle Schichten müssen vollständig mit der nächsten verbunden sein</p>
</li>
<li>
<p>Automatische Extraktion von Eingabe Charakteristika</p>
</li>
<li>
<p>Teilweise rekursiver Aufbau - Teile des Netzwerkes bestehen aus kleineren dedizierten Netzen mit bestimmten Eigenschaften</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Einige der Aspekte sind erst durch höhere Rechenleistungen besonders im GPU Umfeld möglich geworden, andere durch neue Erkenntnisse aus der Forschung.</p>
</div>
</div>
<div class="sect2">
<h3 id="_convolutional_neuronale_netzwerke_cnn">Convolutional Neuronale Netzwerke (CNN)</h3>
<div class="paragraph">
<p>Diese neuronalen Netzwerke nutzen Mechanismen aus der Bildverarbeitung insbesondere Kernels um Bilddaten in geeigente Eingabeinformationen für das Netzwerk umzuwandeln.
Anders bisherige Ansätze sind sie sehr robust gegenüber Veränderungen im Bild wie Drehungen, Farb- und Helligkeitsänderungen usw. d.h. sie lernen wirklich die Essenz des Bildes.
Das geschieht durch mehrere hintereinandergeschaltete Netze, die über mehrere Schritte ausgehend von einfachen (Kontrast-)Kanten und Punkten komplexere Gebilde höherer Ordnung wie z.B. Gesichter, Gebäude, Verkehrszeichen, Zahlen, Tiere usw. erkennen können.
Aktuell werden CNN&#8217;s auch für Textverarbeitung eingesetzt, da Texte ähnlich wie Bilder in Ausschnitten betrachtet werden können.</p>
</div>
<div class="paragraph">
<p>CNNs benutzen Tensoren (mehrdimensionale Matritzen/Arrays mit mehr als 3 Dimensionen) um Bilder zu repräsentieren.
Breite und Höhe des Bildes sind die ersten 2 Dimensionen, die Farbinformation die dritte und strukturelle Eigenschaften des Bildes an einem Punkt (z.b. Kanten) die vierte Dimension.</p>
</div>
<div class="paragraph">
<p>Der Name kommt vom lateinischen 'convolvere' was für "zusammenrollen".
Convolution stellt die Überlappung oder Überlagerung zweier Funktionen dar, ähnlich zur Interferenz, eine einfache Variante ist es, einfach beide Funktionen zu multiplizieren.
Dabei stellt die eine Funktion Attribute des Bildes dar, und die zweite einen Filter, der bestimmte Aspekte heraushebt und verstärkt, zum Beispiel ein Kantenfilter über Kontrastwerte.</p>
</div>
<div class="paragraph">
<p>In der ersten Schicht eines CNN werden viele verschiedenen Filterfunktionen auf dasselbe Eingangsbild angewandt, um unterschiedliche Aspekte hervorzuheben.
Im Tensor werden dann diese Eigenschaften pro Bildpunkt und Farbe hinterlegt.
Für die Weiterverarbeitung werden diese Eigenschaften auf einen 0..1 Wertebereich normalisiert.</p>
</div>
<div class="paragraph">
<p>RGB-Farbwerte und damit Kontraste, Helligkeiten usw. werden über Strukturmuster vieler 3x3 Kernel-Matrix-Filter verstärkt und selektiert, wie sie auch aus der Bildverarbeitung bekannt sind.
Die Aufgabe des Netzwerkes ist es herauszufinden, welche Farben und Strukturen relevant für die Erkennungsleistung sind.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://deeplearning4j.org/img/karpathy-convnet-labels.png" alt="karpathy convnet labels">
</div>
</div>
<div class="paragraph">
<p>Durch diesen Ansatz und eine geeignete Wahl der Filterfrequenz (Schrittweite) kann die Bildinformation auf eine Anzahl kleiner, spezifischer Matritzen reduziert werden.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://deeplearning4j.org/img/convnet.png" alt="convnet">
</div>
</div>
<div class="paragraph">
<p>In weiteren Schichten werden diese Matritzen weiter reduziert, z.b. durch eine Maximumselektion und weitere, wiederholte Eigenschaftsfilter auf dann höheren Abstraktionsleveln.
Wenn die Eigenschaftsmatritzen klein genug sind (z.b. 32x32), können sie dann mit regulären Feed-Forward-Netzen klassifiziert werden.</p>
</div>
</div>
<div class="sect2">
<h3 id="_recurrent_neuronale_netzwerke">Recurrent Neuronale Netzwerke</h3>
<div class="paragraph">
<p>Wenn die Eingabedaten sich über einen Zeitverlauf ändern (Features mit Zeitstempel), dann ist es nützlich wenn unser Netzwerk Zusammenhänge über die Zeit erkennen kann.
Ähnlich wie bei Bildern, werden spezifische Mustern und Eigenheiten erkannt, diesmal aber in der zwei- (oder mehr-)dimensionalen Abbildung des Werteverlaufs über die Zeit.</p>
</div>
<div class="paragraph">
<p>Zum einen können Werte innerhalb eines wandernden Zeitfensters als einzelne Eingaben betrachtet werden, zum anderen erinnern sich RNNs an vergangene Muster.</p>
</div>
<div class="paragraph">
<p>Das ist mit einem Gedächtnis möglich, das den vorherigen Aktivierungszustand in die aktuelle Auswertung einfliessen lässt.</p>
</div>
<div class="paragraph">
<p>Für Videos zB. kann eine Mischung aus RNN (Long Short Term Memory (LSTM)) und CNN genutzt werden, um sowohl den Zeit-Aspekt als auch die Bildverarbeitung abzudecken.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_hello_world">Hello World</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_xor_mittels_feed_forward_netzwerk">XOR mittels Feed Forward Netzwerk</h3>
<div class="paragraph">
<p>Das erste Neuronale Netz, das Perceptron, hatte noch keine Zwischenschichten, und konnte damit nur lineare Abbildungen vornehmen.
Eine nichtlineare Aufgabe wie ein XOR funktionierte damit nicht.</p>
</div>
<div class="paragraph">
<p>Wir können es aber einfach mit einem Netz mit zwei Eingaben, zwei Neuronen in der versteckten Schicht und einer Ausgabe modellieren.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://dl.dropboxusercontent.com/u/14493611/ml_xor.png" alt="ml xor" width="400">
</div>
</div>
<div class="paragraph">
<p>Wenn man die Eingaben auf die Paare (0,0) oder (1,1) setzt, erhält man nach der Berechnung 0, sonst 1 am Ausgang.</p>
</div>
<div class="paragraph">
<p>Mittels der sigmoid Aktivierungsfunktion erhält man für Eingabesummen deutlich kleiner als Null eine 0 und deutlich größer als Null eine 1.</p>
</div>
<div class="paragraph">
<p>Anbei die Berechnungstabelle für 2 Beispielbelegungen:</p>
</div>
<table class="tableblock frame-all grid-all fit-content">
<colgroup>
<col>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">input1</th>
<th class="tableblock halign-left valign-top">input2</th>
<th class="tableblock halign-left valign-top">hidden1</th>
<th class="tableblock halign-left valign-top">hidden2</th>
<th class="tableblock halign-left valign-top">output</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>0</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">sigmoid(-10 + 0*20 + 1*20) = s(10) = 1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">sigmoid(30 + 0*-20 + 1*-20) = s( 10) = 1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">sigmoid(-30 + 1*20 + 1*20) = s( 10) = 1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">sigmoid(-10 + 1*20 + 1*20) = s(30) = 1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">sigmoid(30 + 1*-20 + 1*-20) = s(-10) = 0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">sigmoid(-30 + 1*20 + 0*20) = s(-10) = 0</p></td>
</tr>
</tbody>
</table>
<div class="imageblock">
<div class="content">
<img src="https://dl.dropboxusercontent.com/u/14493611/ml_xor_11.png" alt="ml xor 11" width="400">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_bilderkennung">Bilderkennung</h3>
<div class="paragraph">
<p>Für die Bilderkennung stellt die Klassifizierung von handschriftlichen Zahlen (70000 Beispiele im MNIST Datenset) das gängige "Hello World" dar.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="https://dl.dropboxusercontent.com/u/14493611/MNIST.png" alt="MNIST" width="400">
</div>
</div>
<div class="paragraph">
<p>Im einfachsten Fall, werden die 28x28 Pixel Bilder auf entsprechend 784 Eingabe-Neuronen für den jeweiligen Grauwert abgebildet, und
mittels Feed-Forward-Netzwerk klassifiziert, und auf die 10 Zahlen (Klassen) abgebildet.
Dafür werden andere Aktivierungsfunktionen (ReLU und SoftMax) benutzt aber ansonsten ist es ein klassisches Netzwerk.</p>
</div>
<div class="paragraph">
<p>Man kann die Bilder der Zahlen aber auch über ein CNN vorverarbeiten und damit relevante Eigenschaften (vor allem Kanten und Kurven) herausfiltern.</p>
</div>
<div class="paragraph">
<p>Dafür werden zuerst die Kanteninformationen des Bildes mittels eines Bildverarbeitungs-Kernels der Convolutional Schichten umgewandelt und in den Subsampling Schichten weiter reduziert.
Wenn wir dann genügend wenig abstrahierte Eigenschaften zur Verfügung haben, können wir wieder unser vertrautes FeedForward Netzwerk zur Klassifikation einsetzen.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_deeplearning4j">Deeplearning4j</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Im Java Umfeld hat sich Deeplearning4j [DL4J] - gut erkenntbar an der vertrauten "4j" Endung hervorgetan.
Es ist unter der Apache 2.0 Lizenz verfügbar und kann von Java, Kotlin, Groovy, Scala und Clojure aus benutzt werden.
Deeplearning4j ist unter Berücksichtigung von aktuellen Erkenntnissen und Plattformen in C++ und Java entwickelt worden und stellt Dienste zur Modellierung, Eingabe-Vektorisierung (via DataVec Bibliothek), Auswertung und Datenintegration bereit.
Die API von DL4J erlaubt die Konstruktion, Konfiguration, Tuning, Training, Auswertung und Nutzung komplexer neuronaler Netze.
Die Laufzeitumgebung von DL4J basiert auf einer effizienten Implementierung für n-dimensionale Felder (ND4J) für CPU und GPU, die effiziente, wissenschaftliche (Matrix-)Berechnungen ermöglicht. Die kompakte, einfache Syntax von ND4J ähnelt der von Pythons Numpy und Matlab.
Die Bibliothek kann sich bei Bedarf sowohl Grafikprozessor- als auch Hadoop- und Spark Cluster für das Training der Netze zu Nutze machen.</p>
</div>
<div class="paragraph">
<p>Das O&#8217;Reilly Buch "Deep Learning - A Practitioner&#8217;s Approach" [Dl4JBuch] der Initiatoren von DL4J, Adam Gibson und Josh Patterson ist gerade erst im August erschienen, und sehr zu empfehlen.
An manchen Stellen etwas knapp gehalten führt es doch sehr gut ins Thema der Neuronalen Netze und des Deep-Learning ein, und zeigt im zweiten Teil, wie die Konzepte konkret mit der Bibliothek umgesetzt werden können.</p>
</div>
<div class="paragraph">
<p>Das wollen wir im folgenden für einige praxisrelevanten Beispiele nachvollziehen, die meisten Deeplearning4j-Bespiele sind in einem separaten GitHub Repository [DL4JBeispiele] verfügbar.</p>
</div>
<div class="paragraph">
<p>Deeplearning4j&#8217;s API erlauben die Konfiguration des Neuronalen Netzwerkes via einer Builder API.
Zuerst werden globalen Eigenschaften des Netzwerkes, wie Lernrate, Optimitierungsalgorithmus, Anzahl der Trainingsiterationen,  und andere gesetzt.</p>
</div>
<div class="sect2">
<h3 id="_api_beispiel_xor">API Beispiel XOR</h3>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">ListBuilder builder = new NeuralNetConfiguration.Builder()
  .seed(123)
  .iterations(1)
  .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)
  .learningRate(0.1)
  .list()</code></pre>
</div>
</div>
<div class="paragraph">
<p>Dann werden die Schichten des Netzwerkes - Eingabe, Verarbietung und Ausgabe definiert.
Zum Schluss legen wir noch fest, dass wir kein Vortraining des Netzes vornehmen und Backpropagation benutzten wollen.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">MultiLayerConfiguration conf = builder
  .layer(0, new DenseLayer.Builder().nIn(2).nOut(2)
  .weightInit(WeightInit.DISTRIBUTION).dist(new UniformDistribution(0,1))
  .activation(Activation.SIGMOID)
  .build())

  .layer(1, new OutputLayer.Builder(LossFunctions.LossFunction.MSE).nIn(2).nOut(1)
  .weightInit(WeightInit.DISTRIBUTION).dist(new UniformDistribution(0,1))
  .activation(Activation.SIGMOID).build())

  .pretrain(false).backprop(true).build();</code></pre>
</div>
</div>
<div class="paragraph">
<p>Mit der resultierenden Konfiguration können wir jetzt ein Netzwerk initialisieren und trainieren.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">MultiLayerNetwork model = new MultiLayerNetwork(conf);
model.init();
model.setListeners(new ScoreIterationListener(10));</code></pre>
</div>
</div>
<div class="paragraph">
<p>Die Trainingsdaten liegen dabei als mehrdimensionale Felder (<code>NDArray</code>) in <code>DataSet</code> vor, das jeweils Eingaben und erwartete Ausgaben enthält.
Diese können mit Hilfsklassen aus Dateien oder Datenbanken geladen werden.</p>
</div>
<div class="paragraph">
<p>Über einen <code>DataSetIterator</code> werden die Daten dann in kleinen Gruppen (Microbatches) dem Netzwerk zum Training</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">DoublesDataSetIterator iterator = new DoublesDataSetIterator(
  Arrays.asList(
    makePair(new double[] {0,0},new double[] {0}),
    makePair(new double[] {0,1},new double[] {1}),
    makePair(new double[] {1,0},new double[] {1}),
    makePair(new double[] {1,1},new double[] {0})), 1);

for (int n = 0; n &lt; 10000; n++) {
  model.fit(iterator);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Danach können wir unser Modell evaluieren.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">Evaluation eval = model.evaluate(iterator);
eval.getPredictionErrors().forEach( p -&gt;
  System.out.printf("Predicted: %d, Actual: %d%n", p.getPredictedClass(), p.getActualClass())
);
System.out.println(eval.stats());</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>Examples labeled as 0 classified by model as 0: 2 times
Examples labeled as 1 classified by model as 1: 2 times

==========================Scores========================================
 Accuracy:        1
 Precision:       1
 Recall:          1
 F1 Score:        1
========================================================================</pre>
</div>
</div>
<div class="exampleblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>Accuracy - Der Anteil der korrekt identifizierten Eingaben (true positive, false negative), generelle Qualität.</p>
</li>
<li>
<p>Precision - Anzahl der korrekten Ergebnisse Klasse 1 (true positive) durch Anzahl aller korrekten und inkorrekten Klasse 1 (true und false positive).</p>
</li>
<li>
<p>Recall - Anzahl der korrekten Klasse 1 (true positive) durch die Anzahl der korrekt identifizierten Ergebnisse (true positive, false negative).</p>
</li>
<li>
<p>F1 Score - Gewichteter Durchschnitt von Precision und Recall.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Präzision, Recall und F1 messen die Relevanz des Modells.  Das ist besonders bei Modellen wichtig, deren "false negatives" kritische Auswirkungen haben.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Und natürlich auch benutzen.
Hier mittels Regression, die unsere einzige Ausgabe auf 0..1 abbildet mit <code>model.predict</code> kann man dagegen Klassifikationen vornehmen.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">INDArray data = Nd4j.zeros(2, 2);

data.putScalar(0,0,0d);
data.putScalar(0,1,1d);

data.putScalar(1,0,1d);
data.putScalar(1,1,1d);

INDArray output = model.output(data);

for (int i=0;i&lt;data.rows();i++) {
    System.out.println(data.getRow(i) +" -&gt; "+ output.getRow(i));
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>[0.00, 1.00] -&gt; 0.96
[1.00, 1.00] -&gt; 0.04</pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_api_beispiel_mnist_convolutional_netzwerk">API Beispiel MNIST Convolutional Netzwerk</h3>
<div class="paragraph">
<p>Um mit Deeplearning4j ein CNN zu definieren kann man die Hilfe eines speziellen <code>InputType</code> in Anspruch nehmen,
der sich um zusätzliche Konfiguration und die korrekte Anzahl von Elementen für Convolutional und SubSampling-Schichten kümmert.</p>
</div>
<div class="paragraph">
<p>Ansonsten gibt man die Auflösung und die Farbkanäle des Bildes an. Und definiert dann die Abfolge der Schichten.
Hier ist es:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Convolutional</p>
</li>
<li>
<p>SubSampling</p>
</li>
<li>
<p>Convolutional</p>
</li>
<li>
<p>SubSampling</p>
</li>
<li>
<p>FeedForward</p>
</li>
<li>
<p>Ausgabe (Klassifikation auf 10)</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
... global parameters ...

// 5x5 matrix, stride 1, 20 filter
.layer(0, new ConvolutionLayer.Builder(5, 5)
  // nIn and nOut specify depth. nOut is the number of filters to be applied
  .nIn(1).nOut(20).activation(Activation.IDENTITY)
  .stride(1, 1).build())

// 2x2 kernel, stride 2 = 1/4
.layer(1, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)
  .kernelSize(2,2).stride(2,2).build())

// 5x5 matrix, stride 1, 50 filter
.layer(2, new ConvolutionLayer.Builder(5, 5)
  // Note that nIn need not be specified in later layers
  .nOut(50).activation(Activation.IDENTITY)
  .stride(1, 1).build())

// 2x2 kernel, stride 2 = 1/4
.layer(3, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)
  .kernelSize(2,2).stride(2,2).build())

// feed forward layer
.layer(4, new DenseLayer.Builder().activation(Activation.RELU)
  .nOut(500).build())

.layer(5, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)
        .nOut(10) // 10 classes
        .activation(Activation.SOFTMAX).build())

.setInputType(InputType.convolutionalFlat(28,28,1)) //28x28 pixel, 1 color
.backprop(true).pretrain(false).build();</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">DataSetIterator mnistTrain = new MnistDataSetIterator(batchSize,true,123);
DataSetIterator mnistTest  = new MnistDataSetIterator(batchSize,false,123);

MultiLayerNetwork model = new MultiLayerNetwork(conf);
model.init();
model.setListeners(new ScoreIterationListener(1));

for( int i=0; i&lt;nEpochs; i++ ) {
    model.fit(mnistTrain);

    Evaluation eval = model.evaluate(mnistTest);
    Sytem.out.println(eval.stats());
    mnistTest.reset();
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_referenzen">Referenzen</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>[WikiDeepLearning] <a href="https://en.wikipedia.org/wiki/Deep_learning" class="bare">https://en.wikipedia.org/wiki/Deep_learning</a></p>
</li>
<li>
<p>[DL4J] <a href="http://deeplearning4j.com" class="bare">http://deeplearning4j.com</a></p>
</li>
<li>
<p>[DL4JDocs] <a href="https://deeplearning4j.org/documentation" class="bare">https://deeplearning4j.org/documentation</a></p>
</li>
<li>
<p>[AktivierungsFunktionen] <a href="https://en.wikipedia.org/wiki/Activation_function" class="bare">https://en.wikipedia.org/wiki/Activation_function</a></p>
</li>
<li>
<p>[DL4JBeispiele] <a href="https://github.com/deeplearning4j/dl4j-examples" class="bare">https://github.com/deeplearning4j/dl4j-examples</a></p>
</li>
<li>
<p>[MNISTIntro] <a href="https://deeplearning4j.org/mnist-for-beginners" class="bare">https://deeplearning4j.org/mnist-for-beginners</a></p>
</li>
<li>
<p>[DL4JBuch] <a href="http://shop.oreilly.com/product/0636920035343.do" class="bare">http://shop.oreilly.com/product/0636920035343.do</a></p>
</li>
<li>
<p>[DL4JBuchBeispiele] <a href="https://github.com/deeplearning4j/oreilly-book-dl4j-examples" class="bare">https://github.com/deeplearning4j/oreilly-book-dl4j-examples</a></p>
</li>
</ul>
</div>
</div>
</div>

</div>


  <div id='wikifoot' class="footnav">
    <div style="text-align:right; float:right" class='lastmod'>Last updated 2018-10-21 23:33:58 CEST</div>
	
      <div style="text-align:center;">
      <a href='http://jexp.de/impressum'>Impressum</a>
    - <a class='urllink' href='https://twitter.com/mesirii'>Twitter</a>
	- <a class='urllink' href='https://github.com/jexp'>GitHub</a>
	- <a class='urllink' href='https://stackoverflow.com/users/story/728812'>StackOverflow</a>
	- <a class='urllink' href='https://linkedin.com/jexpde'>LinkedIn</a>
	- <a class='urllink' href='https://medium.com/@mesirii'>Medium</a>
	
   </div>

</body>
</html>